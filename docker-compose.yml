version: '3.8'

services:
  # CallBot main application
  callbot:
    build: .
    container_name: callbot-app
    network_mode: "host"  # This allows direct network access
    environment:
      - FLASK_ENV=production
      - SECRET_KEY=your-secret-key-change-in-production
      - DATABASE_URL=sqlite:///callbot.db
      - SIP_DOMAIN=your-sip-server.com
      - SIP_USERNAME=1001
      - SIP_PASSWORD=password
      # Remote Ollama configuration - change this to your remote Ollama URL
      - OLLAMA_URL=${OLLAMA_URL:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama2}
      - TTS_ENGINE=coqui
      - WHISPER_MODEL_SIZE=base
      - WHISPER_DEVICE=cpu
    volumes:
      - ./audio_output:/app/audio_output
      - ./logs:/app/logs
      - callbot_data:/app/data
    depends_on:
      - redis
    restart: unless-stopped

  # Ollama AI service (optional - can use remote Ollama instead)
  ollama:
    image: ollama/ollama:latest
    container_name: callbot-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - callbot-network
    profiles:
      - local-ollama

  # Redis for caching and background tasks
  redis:
    image: redis:7-alpine
    container_name: callbot-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - callbot-network

  # Optional: Nginx reverse proxy
  nginx:
    image: nginx:alpine
    container_name: callbot-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - callbot
    restart: unless-stopped
    networks:
      - callbot-network
    profiles:
      - production

volumes:
  callbot_data:
    driver: local
  ollama_data:
    driver: local
  redis_data:
    driver: local

networks:
  callbot-network:
    driver: bridge 